{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.functions_secondaparte import *\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from scipy.stats import skew\n",
    "\n",
    "# load and display an image with Matplotlib\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 2\n",
    "NOTA:\n",
    "- In questa fase, le immagini da inserire nel database saranno etichettate come image-X-Y- Z.png, dove\n",
    "    - X ∈ {cc, con, detail, emboss, jitter, neg, noise1, noise2, original, poster, rot, smooth, stipple} denota il tipo dell’immagine;\n",
    "    - 1≤Y≤40denota ilsubjectID,and\n",
    "    - 1 ≤ Z ≤ 10 denota l’ ID del campione dell’immagine.\n",
    "    \n",
    "\n",
    "- I task in questa fase riguardano i tre modelli di feature e le misure di distanza/similarita’ sviluppate nella precedente.\n",
    " \n",
    "- Potete usare le librerie esistenti per la decomposizione LDA.\n",
    "- Potete usare le librerie esistenti per l’estrazione di autovalori e autovettori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 2\n",
    "NOTA:\n",
    "- In questa fase, le immagini da inserire nel database saranno etichettate come image-X-Y- Z.png, dove\n",
    "    - X ∈ {cc, con, detail, emboss, jitter, neg, noise1, noise2, original, poster, rot, smooth, stipple} denota il tipo dell’immagine;\n",
    "    - 1≤Y≤40denota ilsubjectID,and\n",
    "    - 1 ≤ Z ≤ 10 denota l’ ID del campione dell’immagine.\n",
    "    \n",
    "\n",
    "- I task in questa fase riguardano i tre modelli di feature e le misure di distanza/similarita’ sviluppate nella precedente.\n",
    " \n",
    "- Potete usare le librerie esistenti per la decomposizione LDA.\n",
    "- Potete usare le librerie esistenti per l’estrazione di autovalori e autovettori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "Implementare un programma che , dati (a) uno dei tre modelli di feature, (b) un valore per X specificato dall’utente, (c) un valore “k” specificato dall’utente, (d) una delle 3 tecniche di riduzione della dimensionalita’ (PCA, SVD, LDA) scelta dall’utente, restituisca le top-k semantiche latenti estratte utilizzando immagini del tipo specificato.\n",
    "\n",
    "> **Nota bene:** Ciascuna semantica latente deve essere presentata sotto forma di sequenza di coppie soggetto-peso, ordinate in modo decrescente rispetto ai pesi. Salvate le semantiche latenti in un file di output opportunamente etichettato (ossia, con nome informativo).\n",
    "\n",
    "> **DA SISTEMARE:** DOBBIAMO CALCOLARE TANTE SEMANTICHE LATENTI QUANTE SONO QUELLE DI PARTENZA E POI RESTITUIAMO LE TOP K\n",
    "\n",
    "\n",
    "# Task 2\n",
    "Implementare un programma che, dati (a) uno dei tre modelli di feature, (b) un valore per Y specificato dall’utente, (c) un valore “k” specificato dall’utente (d) ) una delle 3 tecniche di riduzione della dimensionalita’ (PCA, SVD, LDA) scelta dall’utente, restituisca le top-k semantiche latenti estratte utilizzando immagini del soggetto specificato.\n",
    "\n",
    "> **Nota bene:** Ciascuna semantica latente deve essere presentata sotto forma di sequenza di coppie tipo- peso, ordinate in modo decrescente rispetto ai pesi. Salvate le semantiche latenti in un file di output opportunamente etichettato (ossia, con nome informativo).\n",
    "\n",
    "> **DA SISTEMARE:** DOBBIAMO CALCOLARE TANTE SEMANTICHE LATENTI QUANTE SONO QUELLE DI PARTENZA E POI RESTITUIAMO LE TOP K\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementazione PCA\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ottieniKSemanticheLatenti('LBP', 'cc', 30, 'PCA', 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ottieniKSemanticheLatenti('LBP', '1', 30, 'PCA', 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementazione SVD\n",
    "https://machinelearningmastery.com/singular-value-decomposition-for-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di file su cui applichiamo i metodi:  399\n",
      "SONO IN COLOR MOMENTS\n",
      "Lunghezza di un descrittore:  192\n",
      "Numero di oggetti:  399\n",
      "SONO IN SVD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/extmath.py:368: FutureWarning: If 'random_state' is not supplied, the current default is to use 0 as a fixed seed. This will change to  None in version 1.2 leading to non-deterministic results that better reflect nature of the randomized_svd solver. If you want to silence this warning, set 'random_state' to an integer seed or to None explicitly depending if you want your code to be deterministic or not.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numero righe di U:  399\n",
      "\n",
      "Numero colonne di U:  192\n",
      "\n",
      "Numero righe di S:  192\n",
      "\n",
      "Numero colonne di S:  192\n",
      "\n",
      "Numero righe di VT:  192\n",
      "\n",
      "Numero colonne di VT:  192\n",
      "\n",
      "Left Singular Vectors:\n",
      "[[ 0.05110873 -0.03262629  0.06801898 ...  0.09277528  0.06002658\n",
      "  -0.02973467]\n",
      " [ 0.05094688 -0.00782124 -0.04062928 ...  0.00905532 -0.0394479\n",
      "  -0.02407805]\n",
      " [ 0.05105606 -0.03643099  0.03945403 ... -0.01772579 -0.01501485\n",
      "   0.01351653]\n",
      " ...\n",
      " [ 0.05017496 -0.02257768 -0.04640452 ...  0.01162497 -0.039152\n",
      "   0.00320716]\n",
      " [ 0.04999384 -0.01653893  0.00151852 ...  0.02605043  0.02508238\n",
      "  -0.02636085]\n",
      " [ 0.05015049 -0.02236306 -0.01045727 ...  0.08497969  0.01953029\n",
      "  -0.03249303]]\n",
      "\n",
      "Singular Values:\n",
      "[[3.69020079e+04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.44331138e+03 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.16571499e+03 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 2.78995561e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  2.60355087e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 2.47472429e+00]]\n",
      "\n",
      "Right Singular Vectors:\n",
      "[[ 0.12488474  0.12527301  0.12484396 ... -0.00068814 -0.00088717\n",
      "  -0.00094072]\n",
      " [-0.01069986  0.0114923  -0.01121644 ... -0.00101471 -0.00171532\n",
      "  -0.00297149]\n",
      " [ 0.03749635  0.04234823  0.00425611 ... -0.00041238 -0.00039126\n",
      "   0.00198301]\n",
      " ...\n",
      " [ 0.00945677  0.00742224 -0.01124168 ... -0.1011224   0.01811635\n",
      "   0.0546814 ]\n",
      " [ 0.00380494 -0.01179094 -0.0007549  ... -0.01450329 -0.05550227\n",
      "  -0.00605361]\n",
      " [ 0.00188574 -0.01185306 -0.00748942 ... -0.04824891 -0.05238642\n",
      "  -0.00741693]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ottieniKSemanticheLatenti('ColorMoments', 'cc', 30, 'SVD', 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ottieniKSemanticheLatenti' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Volumes/DATI/GIT/Progetto_DBM/Task Puliti/task1_secondaparte.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Volumes/DATI/GIT/Progetto_DBM/Task%20Puliti/task1_secondaparte.ipynb#ch0000019?line=0'>1</a>\u001b[0m ottieniKSemanticheLatenti(\u001b[39m'\u001b[39m\u001b[39mColorMoments\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39memboss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m30\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSVD\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ottieniKSemanticheLatenti' is not defined"
     ]
    }
   ],
   "source": [
    "ottieniKSemanticheLatenti('ColorMoments', 'emboss', 30, 'SVD', 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ottieniKSemanticheLatenti('ColorMoments', '1', 30, 'SVD', 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementazione LDA\n",
    "\n",
    "> **Nota bene:** Con LDA possiamo non utilizzare ColorMoments\n",
    "\n",
    "Link articolo utie: https://pages.cs.wisc.edu/~pradheep/Clust-LDA.pdf\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\n",
    "\n",
    "https://machinelearninggeek.com/latent-dirichlet-allocation-using-scikit-learn/\n",
    "\n",
    "https://machinelearningmastery.com/linear-discriminant-analysis-for-dimensionality-reduction-in-python/\n",
    "\n",
    "https://scikit-learn.org/0.16/modules/generated/sklearn.lda.LDA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ottieniKSemanticheLatenti('HOG', 'cc', 3, 'LDA', 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ottieniKSemanticheLatenti('HOG', '1', 3, 'LDA', 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domande\n",
    "\n",
    "> **Domanda 1:** \"ciasuna feature latente deve essere espressa come una sequenza di coppie soggetto-peso\". Cosa intendiamo con \"peso\"? Il contriuto che quella feature latente dà a quel soggetto? (Quindi dobbiamo leggere la maatrice U che descrive gli oggetti rispetto alle feature latenti). Oppure si intende il peso associato alla feature latente per poter ricostruire il db di partenza?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8\n",
    "\n",
    "Algoritmo page-rank: https://www.geeksforgeeks.org/page-rank-algorithm-implementation/\n",
    "\n",
    "Costruire un grafo - *GUARDARE QUESTO*: https://networkx.org/documentation/stable/tutorial.html\n",
    "\n",
    "https://www.meccanismocomplesso.org/programming-graphs-in-python-part-1-grafi/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

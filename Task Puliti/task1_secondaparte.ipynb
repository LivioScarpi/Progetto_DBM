{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.functions_secondaparte import *\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from scipy.stats import skew\n",
    "\n",
    "# load and display an image with Matplotlib\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 2\n",
    "NOTA:\n",
    "- In questa fase, le immagini da inserire nel database saranno etichettate come image-X-Y-Z.png, dove\n",
    "    - X ∈ {cc, con, detail, emboss, jitter, neg, noise1, noise2, original, poster, rot, smooth, stipple} denota il tipo dell’immagine;\n",
    "    - 1≤Y≤40 denota il subjectID, e\n",
    "    - 1 ≤ Z ≤ 10 denota l’ ID del campione dell’immagine.\n",
    "    \n",
    "\n",
    "- I task in questa fase riguardano i tre modelli di feature e le misure di distanza/similarita’ sviluppate nella precedente.\n",
    " \n",
    "- Potete usare le librerie esistenti per la decomposizione LDA.\n",
    "- Potete usare le librerie esistenti per l’estrazione di autovalori e autovettori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "Implementare un programma che , dati (a) uno dei tre modelli di feature, (b) un valore per X specificato dall’utente, (c) un valore “k” specificato dall’utente, (d) una delle 3 tecniche di riduzione della dimensionalita’ (PCA, SVD, LDA) scelta dall’utente, restituisca le top-k semantiche latenti estratte utilizzando immagini del tipo specificato.\n",
    "\n",
    "> **Nota bene:** Ciascuna semantica latente deve essere presentata sotto forma di sequenza di coppie soggetto-peso, ordinate in modo decrescente rispetto ai pesi. Salvate le semantiche latenti in un file di output opportunamente etichettato (ossia, con nome informativo).\n",
    "\n",
    "> **OPZIONALE:** DOBBIAMO CALCOLARE TANTE SEMANTICHE LATENTI QUANTE SONO QUELLE DI PARTENZA E POI RESTITUIAMO LE TOP K\n",
    "\n",
    "\n",
    "# Task 2\n",
    "Implementare un programma che, dati (a) uno dei tre modelli di feature, (b) un valore per Y specificato dall’utente, (c) un valore “k” specificato dall’utente (d) ) una delle 3 tecniche di riduzione della dimensionalita’ (PCA, SVD, LDA) scelta dall’utente, restituisca le top-k semantiche latenti estratte utilizzando immagini del soggetto specificato.\n",
    "\n",
    "> **Nota bene:** Ciascuna semantica latente deve essere presentata sotto forma di sequenza di coppie tipo- peso, ordinate in modo decrescente rispetto ai pesi. Salvate le semantiche latenti in un file di output opportunamente etichettato (ossia, con nome informativo).\n",
    "\n",
    "> **OPZIONALE:** DOBBIAMO CALCOLARE TANTE SEMANTICHE LATENTI QUANTE SONO QUELLE DI PARTENZA E POI RESTITUIAMO LE TOP K\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementazione PCA\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ottieniKSemanticheLatenti('LBP', 'cc', 30, 'PCA', 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ottieniKSemanticheLatenti('LBP', '1', 30, 'PCA', 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementazione SVD\n",
    "https://machinelearningmastery.com/singular-value-decomposition-for-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di file su cui applichiamo i metodi:  399\n",
      "SONO IN COLOR MOMENTS\n",
      "Lunghezza di un descrittore:  192\n",
      "Numero di oggetti:  399\n",
      "SONO IN SVD\n",
      "\n",
      "converted_data_test:\n",
      "[[ 1.88601477e+03 -4.70899022e+01  7.92907397e+01 ... -1.09985022e-01\n",
      "   2.58838899e-01  1.56282242e-01]\n",
      " [ 1.88004219e+03 -1.12884798e+01 -4.73621611e+01 ...  3.28691868e-02\n",
      "   2.52639526e-02 -1.02704626e-01]\n",
      " [ 1.88407120e+03 -5.25812602e+01  4.59921532e+01 ...  9.79419979e-02\n",
      "  -4.94541706e-02 -3.90919244e-02]\n",
      " ...\n",
      " [ 1.85155659e+03 -3.25866172e+01 -5.40944434e+01 ...  2.18709193e-01\n",
      "   3.24331536e-02 -1.01934215e-01]\n",
      " [ 1.84487324e+03 -2.38708248e+01  1.77015882e+00 ... -1.80440218e-01\n",
      "   7.26795426e-02  6.53032562e-02]\n",
      " [ 1.85065378e+03 -3.22768605e+01 -1.21901982e+01 ...  3.44786503e-02\n",
      "   2.37089565e-01  5.08480961e-02]]\n",
      "\n",
      "Left Singular Vectors:\n",
      "[[ 0.05110873 -0.03262629  0.06801898 ...  0.09277528  0.06002658\n",
      "  -0.02973467]\n",
      " [ 0.05094688 -0.00782124 -0.04062928 ...  0.00905532 -0.0394479\n",
      "  -0.02407805]\n",
      " [ 0.05105606 -0.03643099  0.03945403 ... -0.01772579 -0.01501485\n",
      "   0.01351653]\n",
      " ...\n",
      " [ 0.05017496 -0.02257768 -0.04640452 ...  0.01162497 -0.039152\n",
      "   0.00320716]\n",
      " [ 0.04999384 -0.01653893  0.00151852 ...  0.02605043  0.02508238\n",
      "  -0.02636085]\n",
      " [ 0.05015049 -0.02236306 -0.01045727 ...  0.08497969  0.01953029\n",
      "  -0.03249303]]\n",
      "\n",
      "Singular Values:\n",
      "[[3.69020079e+04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.44331138e+03 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.16571499e+03 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 2.78995561e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  2.60355087e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 2.47472429e+00]]\n",
      "\n",
      "Right Singular Vectors:\n",
      "[[ 0.12488474  0.12527301  0.12484396 ... -0.00068814 -0.00088717\n",
      "  -0.00094072]\n",
      " [-0.01069986  0.0114923  -0.01121644 ... -0.00101471 -0.00171532\n",
      "  -0.00297149]\n",
      " [ 0.03749635  0.04234823  0.00425611 ... -0.00041238 -0.00039126\n",
      "   0.00198301]\n",
      " ...\n",
      " [ 0.00945677  0.00742224 -0.01124168 ... -0.1011224   0.01811635\n",
      "   0.0546814 ]\n",
      " [ 0.00380494 -0.01179094 -0.0007549  ... -0.01450329 -0.05550227\n",
      "  -0.00605361]\n",
      " [ 0.00188574 -0.01185306 -0.00748942 ... -0.04824891 -0.05238642\n",
      "  -0.00741693]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ottieniKSemanticheLatenti('ColorMoments', 'cc', 30, 'SVD', 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ottieniKSemanticheLatenti('ColorMoments', 'original', 30, 'SVD', 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ottieniKSemanticheLatenti('ColorMoments', 'emboss', 30, 'SVD', 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ottieniKSemanticheLatenti('LBP', 'original', 30, 'SVD', 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ottieniKSemanticheLatenti('ColorMoments', '1', 30, 'SVD', 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementazione LDA\n",
    "\n",
    "> **Nota bene:** Con LDA possiamo non utilizzare ColorMoments\n",
    "\n",
    "Link articolo utie: https://pages.cs.wisc.edu/~pradheep/Clust-LDA.pdf\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\n",
    "\n",
    "https://machinelearninggeek.com/latent-dirichlet-allocation-using-scikit-learn/\n",
    "\n",
    "https://machinelearningmastery.com/linear-discriminant-analysis-for-dimensionality-reduction-in-python/\n",
    "\n",
    "https://scikit-learn.org/0.16/modules/generated/sklearn.lda.LDA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ottieniKSemanticheLatenti('HOG', 'cc', 3, 'LDA', 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ottieniKSemanticheLatenti('HOG', '1', 3, 'LDA', 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
